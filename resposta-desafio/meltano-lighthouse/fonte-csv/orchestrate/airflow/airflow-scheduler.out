  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2024-07-03T17:11:11.915-0300[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2024-07-03T17:11:11.915-0300[0m] {[34mexecutor_loader.py:[0m115} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2024-07-03T17:11:11.934-0300[0m] {[34mscheduler_job_runner.py:[0m808} INFO[0m - Starting the scheduler[0m
[[34m2024-07-03T17:11:11.934-0300[0m] {[34mscheduler_job_runner.py:[0m815} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-07-03T17:11:11.938-0300[0m] {[34mmanager.py:[0m169} INFO[0m - Launched DagFileProcessorManager with pid: 181459[0m
[[34m2024-07-03T17:11:11.939-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:11:11.941-0300[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2024-07-03T17:11:11.954-0300] {manager.py:392} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-07-03T17:11:12.257-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:11:00+00:00, run_after=2024-07-03 20:12:00+00:00[0m
[[34m2024-07-03T17:11:12.384-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:10:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:11:12.385-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:11:12.385-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:10:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:11:12.386-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:11:12.386-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:11:12.386-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:11:12.389-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:11:13.037-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:10:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:11:13.105-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:10:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:11:17.012-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:11:17.019-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:10:00+00:00, map_index=-1, run_start_date=2024-07-03 20:11:13.130808+00:00, run_end_date=2024-07-03 20:11:16.722796+00:00, run_duration=3.591988, state=success, executor_state=success, try_number=1, max_tries=0, job_id=2, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:11:12.385317+00:00, queued_by_job_id=1, pid=181467[0m
[[34m2024-07-03T17:11:18.861-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:10:00+00:00: scheduled__2024-07-03T20:10:00+00:00, state:running, queued_at: 2024-07-03 20:11:12.240738+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:11:18.861-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:10:00+00:00, run_id=scheduled__2024-07-03T20:10:00+00:00, run_start_date=2024-07-03 20:11:12.281683+00:00, run_end_date=2024-07-03 20:11:18.861811+00:00, run_duration=6.580128, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:10:00+00:00, data_interval_end=2024-07-03 20:11:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:11:18.864-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:11:00+00:00, run_after=2024-07-03 20:12:00+00:00[0m
[[34m2024-07-03T17:12:01.807-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:12:00+00:00, run_after=2024-07-03 20:13:00+00:00[0m
[[34m2024-07-03T17:12:01.844-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:11:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:12:01.845-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:12:01.845-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:11:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:12:01.847-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:12:01.847-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:11:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:12:01.847-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:12:01.851-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:12:02.515-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:11:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:12:02.579-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:11:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:12:06.091-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:11:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:12:06.095-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:11:00+00:00, map_index=-1, run_start_date=2024-07-03 20:12:02.603751+00:00, run_end_date=2024-07-03 20:12:05.812231+00:00, run_duration=3.20848, state=success, executor_state=success, try_number=1, max_tries=0, job_id=3, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:12:01.846028+00:00, queued_by_job_id=1, pid=181762[0m
[[34m2024-07-03T17:12:06.132-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:11:00+00:00: scheduled__2024-07-03T20:11:00+00:00, state:running, queued_at: 2024-07-03 20:12:01.803040+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:12:06.132-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:11:00+00:00, run_id=scheduled__2024-07-03T20:11:00+00:00, run_start_date=2024-07-03 20:12:01.819582+00:00, run_end_date=2024-07-03 20:12:06.132600+00:00, run_duration=4.313018, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:11:00+00:00, data_interval_end=2024-07-03 20:12:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:12:06.136-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:12:00+00:00, run_after=2024-07-03 20:13:00+00:00[0m
[[34m2024-07-03T17:13:02.672-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:13:00+00:00, run_after=2024-07-03 20:14:00+00:00[0m
[[34m2024-07-03T17:13:02.712-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:12:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:13:02.712-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:13:02.712-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:12:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:13:02.713-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:13:02.714-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:12:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:13:02.714-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:13:02.718-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:13:03.326-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:12:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:13:03.388-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:12:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:13:06.824-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:12:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:13:06.827-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:12:00+00:00, map_index=-1, run_start_date=2024-07-03 20:13:03.413063+00:00, run_end_date=2024-07-03 20:13:06.595174+00:00, run_duration=3.182111, state=success, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:13:02.713102+00:00, queued_by_job_id=1, pid=182097[0m
[[34m2024-07-03T17:13:06.869-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:12:00+00:00: scheduled__2024-07-03T20:12:00+00:00, state:running, queued_at: 2024-07-03 20:13:02.666946+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:13:06.870-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:12:00+00:00, run_id=scheduled__2024-07-03T20:12:00+00:00, run_start_date=2024-07-03 20:13:02.687555+00:00, run_end_date=2024-07-03 20:13:06.870161+00:00, run_duration=4.182606, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:12:00+00:00, data_interval_end=2024-07-03 20:13:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:13:06.874-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:13:00+00:00, run_after=2024-07-03 20:14:00+00:00[0m
[[34m2024-07-03T17:14:01.484-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:14:00+00:00, run_after=2024-07-03 20:15:00+00:00[0m
[[34m2024-07-03T17:14:01.547-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:13:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:14:01.548-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:14:01.548-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:13:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:14:01.551-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:14:01.552-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:13:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:14:01.553-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:14:01.558-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:14:02.210-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:13:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:14:02.274-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:13:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:14:05.620-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:13:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:14:05.624-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:13:00+00:00, map_index=-1, run_start_date=2024-07-03 20:14:02.300818+00:00, run_end_date=2024-07-03 20:14:05.394620+00:00, run_duration=3.093802, state=success, executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:14:01.549843+00:00, queued_by_job_id=1, pid=182490[0m
[[34m2024-07-03T17:14:07.365-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:13:00+00:00: scheduled__2024-07-03T20:13:00+00:00, state:running, queued_at: 2024-07-03 20:14:01.474993+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:14:07.366-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:13:00+00:00, run_id=scheduled__2024-07-03T20:13:00+00:00, run_start_date=2024-07-03 20:14:01.502810+00:00, run_end_date=2024-07-03 20:14:07.366105+00:00, run_duration=5.863295, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:13:00+00:00, data_interval_end=2024-07-03 20:14:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:14:07.368-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:14:00+00:00, run_after=2024-07-03 20:15:00+00:00[0m
[[34m2024-07-03T17:15:01.316-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:15:00+00:00, run_after=2024-07-03 20:16:00+00:00[0m
[[34m2024-07-03T17:15:01.359-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:14:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:15:01.360-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:15:01.360-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:14:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:15:01.362-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:15:01.362-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:14:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:15:01.363-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:15:01.367-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:15:01.985-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:14:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:15:02.051-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:14:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:15:05.431-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:14:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:15:05.437-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:14:00+00:00, map_index=-1, run_start_date=2024-07-03 20:15:02.076449+00:00, run_end_date=2024-07-03 20:15:05.185078+00:00, run_duration=3.108629, state=success, executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:15:01.361083+00:00, queued_by_job_id=1, pid=182954[0m
[[34m2024-07-03T17:15:05.476-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:14:00+00:00: scheduled__2024-07-03T20:14:00+00:00, state:running, queued_at: 2024-07-03 20:15:01.311194+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:15:05.476-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:14:00+00:00, run_id=scheduled__2024-07-03T20:14:00+00:00, run_start_date=2024-07-03 20:15:01.330987+00:00, run_end_date=2024-07-03 20:15:05.476506+00:00, run_duration=4.145519, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:14:00+00:00, data_interval_end=2024-07-03 20:15:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:15:05.481-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:15:00+00:00, run_after=2024-07-03 20:16:00+00:00[0m
[[34m2024-07-03T17:16:01.500-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:16:00+00:00, run_after=2024-07-03 20:17:00+00:00[0m
[[34m2024-07-03T17:16:01.522-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:15:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:16:01.522-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:16:01.522-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:15:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:16:01.523-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:16:01.523-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:15:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:16:01.524-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:16:01.527-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:16:02.159-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:15:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:16:02.233-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:15:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:16:05.302-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:15:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:16:05.306-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:15:00+00:00, map_index=-1, run_start_date=2024-07-03 20:16:02.257879+00:00, run_end_date=2024-07-03 20:16:05.068192+00:00, run_duration=2.810313, state=success, executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:16:01.523092+00:00, queued_by_job_id=1, pid=183360[0m
[[34m2024-07-03T17:16:05.337-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:15:00+00:00: scheduled__2024-07-03T20:15:00+00:00, state:running, queued_at: 2024-07-03 20:16:01.498257+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:16:05.337-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:15:00+00:00, run_id=scheduled__2024-07-03T20:15:00+00:00, run_start_date=2024-07-03 20:16:01.507746+00:00, run_end_date=2024-07-03 20:16:05.337631+00:00, run_duration=3.829885, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:15:00+00:00, data_interval_end=2024-07-03 20:16:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:16:05.339-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:16:00+00:00, run_after=2024-07-03 20:17:00+00:00[0m
[[34m2024-07-03T17:16:11.991-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:17:01.133-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:17:00+00:00, run_after=2024-07-03 20:18:00+00:00[0m
[[34m2024-07-03T17:17:01.160-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:16:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:17:01.160-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:17:01.160-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:16:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:17:01.161-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:17:01.162-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:16:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:17:01.162-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:17:01.165-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:17:01.746-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:16:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:17:01.812-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:16:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:17:05.251-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:16:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:17:05.255-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:16:00+00:00, map_index=-1, run_start_date=2024-07-03 20:17:01.841556+00:00, run_end_date=2024-07-03 20:17:05.000429+00:00, run_duration=3.158873, state=success, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:17:01.161000+00:00, queued_by_job_id=1, pid=183700[0m
[[34m2024-07-03T17:17:05.302-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:16:00+00:00: scheduled__2024-07-03T20:16:00+00:00, state:running, queued_at: 2024-07-03 20:17:01.129476+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:17:05.302-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:16:00+00:00, run_id=scheduled__2024-07-03T20:16:00+00:00, run_start_date=2024-07-03 20:17:01.141627+00:00, run_end_date=2024-07-03 20:17:05.302444+00:00, run_duration=4.160817, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:16:00+00:00, data_interval_end=2024-07-03 20:17:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:17:05.306-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:17:00+00:00, run_after=2024-07-03 20:18:00+00:00[0m
[[34m2024-07-03T17:18:01.114-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:18:00+00:00, run_after=2024-07-03 20:19:00+00:00[0m
[[34m2024-07-03T17:18:01.151-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:17:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:18:01.151-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:18:01.151-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:17:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:18:01.152-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:18:01.153-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:17:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:18:01.153-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:18:01.156-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:18:01.756-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:17:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:18:01.818-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:17:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:18:05.044-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:17:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:18:05.050-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:17:00+00:00, map_index=-1, run_start_date=2024-07-03 20:18:01.842778+00:00, run_end_date=2024-07-03 20:18:04.783265+00:00, run_duration=2.940487, state=success, executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:18:01.152132+00:00, queued_by_job_id=1, pid=184037[0m
[[34m2024-07-03T17:18:05.085-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:17:00+00:00: scheduled__2024-07-03T20:17:00+00:00, state:running, queued_at: 2024-07-03 20:18:01.109170+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:18:05.086-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:17:00+00:00, run_id=scheduled__2024-07-03T20:17:00+00:00, run_start_date=2024-07-03 20:18:01.127429+00:00, run_end_date=2024-07-03 20:18:05.086275+00:00, run_duration=3.958846, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:17:00+00:00, data_interval_end=2024-07-03 20:18:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:18:05.090-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:18:00+00:00, run_after=2024-07-03 20:19:00+00:00[0m
[[34m2024-07-03T17:19:01.791-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:19:00+00:00, run_after=2024-07-03 20:20:00+00:00[0m
[[34m2024-07-03T17:19:01.828-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:18:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:19:01.828-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:19:01.828-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:18:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:19:01.829-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:19:01.830-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:18:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:19:01.830-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:19:01.834-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:19:02.436-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:18:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:19:02.498-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:18:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:19:05.838-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:18:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:19:05.841-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:18:00+00:00, map_index=-1, run_start_date=2024-07-03 20:19:02.522773+00:00, run_end_date=2024-07-03 20:19:05.611851+00:00, run_duration=3.089078, state=success, executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:19:01.829055+00:00, queued_by_job_id=1, pid=184396[0m
[[34m2024-07-03T17:19:05.877-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:18:00+00:00: scheduled__2024-07-03T20:18:00+00:00, state:running, queued_at: 2024-07-03 20:19:01.786449+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:19:05.878-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:18:00+00:00, run_id=scheduled__2024-07-03T20:18:00+00:00, run_start_date=2024-07-03 20:19:01.804165+00:00, run_end_date=2024-07-03 20:19:05.878038+00:00, run_duration=4.073873, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:18:00+00:00, data_interval_end=2024-07-03 20:19:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:19:05.882-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:19:00+00:00, run_after=2024-07-03 20:20:00+00:00[0m
[[34m2024-07-03T17:20:01.656-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:20:00+00:00, run_after=2024-07-03 20:21:00+00:00[0m
[[34m2024-07-03T17:20:01.693-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:19:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:20:01.693-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:20:01.693-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:19:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:20:01.694-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:20:01.695-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:19:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:20:01.695-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:20:01.699-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:20:02.307-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:19:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:20:02.386-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:19:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:20:05.780-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:19:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:20:05.785-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:19:00+00:00, map_index=-1, run_start_date=2024-07-03 20:20:02.411291+00:00, run_end_date=2024-07-03 20:20:05.532529+00:00, run_duration=3.121238, state=success, executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:20:01.694187+00:00, queued_by_job_id=1, pid=184818[0m
[[34m2024-07-03T17:20:05.820-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:19:00+00:00: scheduled__2024-07-03T20:19:00+00:00, state:running, queued_at: 2024-07-03 20:20:01.651529+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:20:05.820-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:19:00+00:00, run_id=scheduled__2024-07-03T20:19:00+00:00, run_start_date=2024-07-03 20:20:01.669506+00:00, run_end_date=2024-07-03 20:20:05.820687+00:00, run_duration=4.151181, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:19:00+00:00, data_interval_end=2024-07-03 20:20:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:20:05.825-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:20:00+00:00, run_after=2024-07-03 20:21:00+00:00[0m
[[34m2024-07-03T17:21:01.694-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:21:00+00:00, run_after=2024-07-03 20:22:00+00:00[0m
[[34m2024-07-03T17:21:01.733-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:20:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:21:01.733-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:21:01.733-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:20:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:21:01.735-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:21:01.735-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:20:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:21:01.735-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:21:01.739-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:21:02.351-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:20:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:21:02.413-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:20:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:21:05.774-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:20:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:21:05.780-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:20:00+00:00, map_index=-1, run_start_date=2024-07-03 20:21:02.438147+00:00, run_end_date=2024-07-03 20:21:05.530969+00:00, run_duration=3.092822, state=success, executor_state=success, try_number=1, max_tries=0, job_id=12, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:21:01.734245+00:00, queued_by_job_id=1, pid=185162[0m
[[34m2024-07-03T17:21:05.924-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:20:00+00:00: scheduled__2024-07-03T20:20:00+00:00, state:running, queued_at: 2024-07-03 20:21:01.689315+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:21:05.925-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:20:00+00:00, run_id=scheduled__2024-07-03T20:20:00+00:00, run_start_date=2024-07-03 20:21:01.708269+00:00, run_end_date=2024-07-03 20:21:05.925058+00:00, run_duration=4.216789, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:20:00+00:00, data_interval_end=2024-07-03 20:21:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:21:05.929-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:21:00+00:00, run_after=2024-07-03 20:22:00+00:00[0m
[[34m2024-07-03T17:21:12.052-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:22:01.280-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:22:00+00:00, run_after=2024-07-03 20:23:00+00:00[0m
[[34m2024-07-03T17:22:01.319-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:21:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:22:01.319-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:22:01.319-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:21:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:22:01.321-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:22:01.321-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:21:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:22:01.322-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:22:01.326-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:22:01.960-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:21:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:22:02.031-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:21:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:22:05.602-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:21:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:22:05.605-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:21:00+00:00, map_index=-1, run_start_date=2024-07-03 20:22:02.061744+00:00, run_end_date=2024-07-03 20:22:05.344223+00:00, run_duration=3.282479, state=success, executor_state=success, try_number=1, max_tries=0, job_id=13, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:22:01.320360+00:00, queued_by_job_id=1, pid=185513[0m
[[34m2024-07-03T17:22:05.640-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:21:00+00:00: scheduled__2024-07-03T20:21:00+00:00, state:running, queued_at: 2024-07-03 20:22:01.275593+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:22:05.640-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:21:00+00:00, run_id=scheduled__2024-07-03T20:21:00+00:00, run_start_date=2024-07-03 20:22:01.292550+00:00, run_end_date=2024-07-03 20:22:05.640515+00:00, run_duration=4.347965, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:21:00+00:00, data_interval_end=2024-07-03 20:22:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:22:05.645-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:22:00+00:00, run_after=2024-07-03 20:23:00+00:00[0m
[[34m2024-07-03T17:23:01.265-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:23:00+00:00, run_after=2024-07-03 20:24:00+00:00[0m
[[34m2024-07-03T17:23:01.306-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:22:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:23:01.306-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:23:01.307-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:22:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:23:01.308-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:23:01.309-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:22:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:23:01.309-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:23:01.313-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:23:01.954-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:22:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:23:02.024-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:22:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:23:05.566-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:22:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:23:05.571-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:22:00+00:00, map_index=-1, run_start_date=2024-07-03 20:23:02.054445+00:00, run_end_date=2024-07-03 20:23:05.288992+00:00, run_duration=3.234547, state=success, executor_state=success, try_number=1, max_tries=0, job_id=14, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:23:01.307802+00:00, queued_by_job_id=1, pid=185915[0m
[[34m2024-07-03T17:23:05.607-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:22:00+00:00: scheduled__2024-07-03T20:22:00+00:00, state:running, queued_at: 2024-07-03 20:23:01.258370+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:23:05.607-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:22:00+00:00, run_id=scheduled__2024-07-03T20:22:00+00:00, run_start_date=2024-07-03 20:23:01.280729+00:00, run_end_date=2024-07-03 20:23:05.607568+00:00, run_duration=4.326839, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:22:00+00:00, data_interval_end=2024-07-03 20:23:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:23:05.613-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:23:00+00:00, run_after=2024-07-03 20:24:00+00:00[0m
[[34m2024-07-03T17:24:01.009-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:24:00+00:00, run_after=2024-07-03 20:25:00+00:00[0m
[[34m2024-07-03T17:24:01.040-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:23:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:24:01.041-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:24:01.041-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:23:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:24:01.041-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:24:01.042-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:23:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:24:01.042-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:24:01.045-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:24:01.708-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:23:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:24:01.778-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:23:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:24:05.206-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:23:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:24:05.212-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:23:00+00:00, map_index=-1, run_start_date=2024-07-03 20:24:01.806725+00:00, run_end_date=2024-07-03 20:24:04.948217+00:00, run_duration=3.141492, state=success, executor_state=success, try_number=1, max_tries=0, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:24:01.041476+00:00, queued_by_job_id=1, pid=186301[0m
[[34m2024-07-03T17:24:05.248-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:23:00+00:00: scheduled__2024-07-03T20:23:00+00:00, state:running, queued_at: 2024-07-03 20:24:01.003578+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:24:05.249-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:23:00+00:00, run_id=scheduled__2024-07-03T20:23:00+00:00, run_start_date=2024-07-03 20:24:01.022631+00:00, run_end_date=2024-07-03 20:24:05.249170+00:00, run_duration=4.226539, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:23:00+00:00, data_interval_end=2024-07-03 20:24:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:24:05.252-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:24:00+00:00, run_after=2024-07-03 20:25:00+00:00[0m
[[34m2024-07-03T17:25:02.003-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:25:00+00:00, run_after=2024-07-03 20:26:00+00:00[0m
[[34m2024-07-03T17:25:02.024-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:24:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:25:02.025-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:25:02.025-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:24:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:25:02.025-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:25:02.026-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:24:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:25:02.026-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:25:02.029-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:25:02.719-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:24:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:25:02.790-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:24:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:25:06.443-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:24:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:25:06.447-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:24:00+00:00, map_index=-1, run_start_date=2024-07-03 20:25:02.820978+00:00, run_end_date=2024-07-03 20:25:06.176858+00:00, run_duration=3.35588, state=success, executor_state=success, try_number=1, max_tries=0, job_id=16, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:25:02.025375+00:00, queued_by_job_id=1, pid=186723[0m
[[34m2024-07-03T17:25:06.475-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:24:00+00:00: scheduled__2024-07-03T20:24:00+00:00, state:running, queued_at: 2024-07-03 20:25:02.001561+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:25:06.475-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:24:00+00:00, run_id=scheduled__2024-07-03T20:24:00+00:00, run_start_date=2024-07-03 20:25:02.011341+00:00, run_end_date=2024-07-03 20:25:06.475196+00:00, run_duration=4.463855, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:24:00+00:00, data_interval_end=2024-07-03 20:25:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:25:06.477-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:25:00+00:00, run_after=2024-07-03 20:26:00+00:00[0m
[[34m2024-07-03T17:26:01.938-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:26:00+00:00, run_after=2024-07-03 20:27:00+00:00[0m
[[34m2024-07-03T17:26:01.976-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:25:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:26:01.977-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:26:01.977-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:25:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:26:01.978-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:26:01.979-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:25:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:26:01.979-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:26:01.983-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:26:02.692-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:25:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:26:02.763-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:25:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:26:06.282-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:25:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:26:06.287-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:25:00+00:00, map_index=-1, run_start_date=2024-07-03 20:26:02.791272+00:00, run_end_date=2024-07-03 20:26:05.997976+00:00, run_duration=3.206704, state=success, executor_state=success, try_number=1, max_tries=0, job_id=17, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:26:01.977891+00:00, queued_by_job_id=1, pid=187085[0m
[[34m2024-07-03T17:26:06.315-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:25:00+00:00: scheduled__2024-07-03T20:25:00+00:00, state:running, queued_at: 2024-07-03 20:26:01.933270+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:26:06.315-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:25:00+00:00, run_id=scheduled__2024-07-03T20:25:00+00:00, run_start_date=2024-07-03 20:26:01.952401+00:00, run_end_date=2024-07-03 20:26:06.315329+00:00, run_duration=4.362928, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:25:00+00:00, data_interval_end=2024-07-03 20:26:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:26:06.317-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:26:00+00:00, run_after=2024-07-03 20:27:00+00:00[0m
[[34m2024-07-03T17:26:12.104-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:27:01.199-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:27:00+00:00, run_after=2024-07-03 20:28:00+00:00[0m
[[34m2024-07-03T17:27:01.222-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:26:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:27:01.222-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:27:01.222-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:26:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:27:01.223-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:27:01.223-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:26:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:27:01.223-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:27:01.227-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:27:01.886-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:26:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:27:01.957-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:26:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:27:05.589-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:26:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:27:05.594-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:26:00+00:00, map_index=-1, run_start_date=2024-07-03 20:27:01.984670+00:00, run_end_date=2024-07-03 20:27:05.322887+00:00, run_duration=3.338217, state=success, executor_state=success, try_number=1, max_tries=0, job_id=18, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:27:01.222774+00:00, queued_by_job_id=1, pid=187462[0m
[[34m2024-07-03T17:27:07.438-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:26:00+00:00: scheduled__2024-07-03T20:26:00+00:00, state:running, queued_at: 2024-07-03 20:27:01.196690+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:27:07.438-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:26:00+00:00, run_id=scheduled__2024-07-03T20:26:00+00:00, run_start_date=2024-07-03 20:27:01.206670+00:00, run_end_date=2024-07-03 20:27:07.438677+00:00, run_duration=6.232007, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:26:00+00:00, data_interval_end=2024-07-03 20:27:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:27:07.441-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:27:00+00:00, run_after=2024-07-03 20:28:00+00:00[0m
[[34m2024-07-03T17:28:01.145-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:28:00+00:00, run_after=2024-07-03 20:29:00+00:00[0m
[[34m2024-07-03T17:28:01.168-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:27:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:28:01.168-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:28:01.168-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:27:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:28:01.169-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:28:01.169-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:27:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:28:01.169-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:28:01.174-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:28:01.938-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:27:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:28:02.014-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:27:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:28:05.650-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:27:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:28:05.654-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:27:00+00:00, map_index=-1, run_start_date=2024-07-03 20:28:02.043453+00:00, run_end_date=2024-07-03 20:28:05.418781+00:00, run_duration=3.375328, state=success, executor_state=success, try_number=1, max_tries=0, job_id=19, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:28:01.168764+00:00, queued_by_job_id=1, pid=188007[0m
[[34m2024-07-03T17:28:05.693-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:27:00+00:00: scheduled__2024-07-03T20:27:00+00:00, state:running, queued_at: 2024-07-03 20:28:01.140811+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:28:05.694-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:27:00+00:00, run_id=scheduled__2024-07-03T20:27:00+00:00, run_start_date=2024-07-03 20:28:01.154041+00:00, run_end_date=2024-07-03 20:28:05.694204+00:00, run_duration=4.540163, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:27:00+00:00, data_interval_end=2024-07-03 20:28:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:28:05.698-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:28:00+00:00, run_after=2024-07-03 20:29:00+00:00[0m
[[34m2024-07-03T17:29:01.349-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:29:00+00:00, run_after=2024-07-03 20:30:00+00:00[0m
[[34m2024-07-03T17:29:01.378-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:28:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:29:01.378-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:29:01.378-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:28:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:29:01.379-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:29:01.379-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:28:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:29:01.379-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:29:01.383-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:29:02.149-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:28:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:29:02.252-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:28:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:29:06.062-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:28:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:29:06.067-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:28:00+00:00, map_index=-1, run_start_date=2024-07-03 20:29:02.296382+00:00, run_end_date=2024-07-03 20:29:05.660852+00:00, run_duration=3.36447, state=success, executor_state=success, try_number=1, max_tries=0, job_id=20, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:29:01.378844+00:00, queued_by_job_id=1, pid=188498[0m
[[34m2024-07-03T17:29:06.101-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:28:00+00:00: scheduled__2024-07-03T20:28:00+00:00, state:running, queued_at: 2024-07-03 20:29:01.341749+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:29:06.101-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:28:00+00:00, run_id=scheduled__2024-07-03T20:28:00+00:00, run_start_date=2024-07-03 20:29:01.358490+00:00, run_end_date=2024-07-03 20:29:06.101313+00:00, run_duration=4.742823, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:28:00+00:00, data_interval_end=2024-07-03 20:29:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:29:06.104-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:29:00+00:00, run_after=2024-07-03 20:30:00+00:00[0m
[[34m2024-07-03T17:30:01.041-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:30:00+00:00, run_after=2024-07-03 20:31:00+00:00[0m
[[34m2024-07-03T17:30:01.064-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:29:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:30:01.064-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:30:01.064-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:29:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:30:01.065-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:30:01.065-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:29:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:30:01.066-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:30:01.069-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:30:01.833-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:29:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:30:01.924-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:29:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:30:05.418-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:29:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:30:05.423-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:29:00+00:00, map_index=-1, run_start_date=2024-07-03 20:30:01.961159+00:00, run_end_date=2024-07-03 20:30:05.184015+00:00, run_duration=3.222856, state=success, executor_state=success, try_number=1, max_tries=0, job_id=21, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:30:01.065041+00:00, queued_by_job_id=1, pid=188862[0m
[[34m2024-07-03T17:30:05.460-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:29:00+00:00: scheduled__2024-07-03T20:29:00+00:00, state:running, queued_at: 2024-07-03 20:30:01.037375+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:30:05.461-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:29:00+00:00, run_id=scheduled__2024-07-03T20:29:00+00:00, run_start_date=2024-07-03 20:30:01.049778+00:00, run_end_date=2024-07-03 20:30:05.461756+00:00, run_duration=4.411978, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:29:00+00:00, data_interval_end=2024-07-03 20:30:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:30:05.467-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:30:00+00:00, run_after=2024-07-03 20:31:00+00:00[0m
[[34m2024-07-03T17:31:01.093-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:31:00+00:00, run_after=2024-07-03 20:32:00+00:00[0m
[[34m2024-07-03T17:31:01.118-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:30:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:31:01.118-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:31:01.118-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:30:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:31:01.119-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:31:01.120-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:30:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:31:01.120-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:31:01.123-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:31:01.982-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:30:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:31:02.076-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:30:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:31:06.046-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:30:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:31:06.050-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:30:00+00:00, map_index=-1, run_start_date=2024-07-03 20:31:02.105708+00:00, run_end_date=2024-07-03 20:31:05.797719+00:00, run_duration=3.692011, state=success, executor_state=success, try_number=1, max_tries=0, job_id=22, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:31:01.119079+00:00, queued_by_job_id=1, pid=189299[0m
[[34m2024-07-03T17:31:06.076-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:30:00+00:00: scheduled__2024-07-03T20:30:00+00:00, state:running, queued_at: 2024-07-03 20:31:01.090207+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:31:06.076-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:30:00+00:00, run_id=scheduled__2024-07-03T20:30:00+00:00, run_start_date=2024-07-03 20:31:01.102801+00:00, run_end_date=2024-07-03 20:31:06.076366+00:00, run_duration=4.973565, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:30:00+00:00, data_interval_end=2024-07-03 20:31:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:31:06.078-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:31:00+00:00, run_after=2024-07-03 20:32:00+00:00[0m
[[34m2024-07-03T17:31:12.158-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:32:01.756-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:32:00+00:00, run_after=2024-07-03 20:33:00+00:00[0m
[[34m2024-07-03T17:32:01.812-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:31:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:32:01.812-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:32:01.813-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:31:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:32:01.815-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:32:01.816-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:31:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:32:01.816-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:32:01.821-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:32:02.741-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:31:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:32:02.827-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:31:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:32:06.714-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:31:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:32:06.719-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:31:00+00:00, map_index=-1, run_start_date=2024-07-03 20:32:02.871428+00:00, run_end_date=2024-07-03 20:32:06.459288+00:00, run_duration=3.58786, state=success, executor_state=success, try_number=1, max_tries=0, job_id=23, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:32:01.814205+00:00, queued_by_job_id=1, pid=189649[0m
[[34m2024-07-03T17:32:06.785-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:31:00+00:00: scheduled__2024-07-03T20:31:00+00:00, state:running, queued_at: 2024-07-03 20:32:01.747647+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:32:06.786-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:31:00+00:00, run_id=scheduled__2024-07-03T20:31:00+00:00, run_start_date=2024-07-03 20:32:01.777645+00:00, run_end_date=2024-07-03 20:32:06.786530+00:00, run_duration=5.008885, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:31:00+00:00, data_interval_end=2024-07-03 20:32:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:32:06.796-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:32:00+00:00, run_after=2024-07-03 20:33:00+00:00[0m
[[34m2024-07-03T17:33:01.920-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:33:00+00:00, run_after=2024-07-03 20:34:00+00:00[0m
[[34m2024-07-03T17:33:01.994-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:32:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:33:01.994-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:33:01.995-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:32:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:33:01.996-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:33:01.997-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:32:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:33:01.997-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:33:02.002-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:33:02.886-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:32:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:33:02.954-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:32:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:33:06.744-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:32:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:33:06.750-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:32:00+00:00, map_index=-1, run_start_date=2024-07-03 20:33:02.986117+00:00, run_end_date=2024-07-03 20:33:06.481586+00:00, run_duration=3.495469, state=success, executor_state=success, try_number=1, max_tries=0, job_id=24, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:33:01.995497+00:00, queued_by_job_id=1, pid=190010[0m
[[34m2024-07-03T17:33:06.777-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:32:00+00:00: scheduled__2024-07-03T20:32:00+00:00, state:running, queued_at: 2024-07-03 20:33:01.891358+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:33:06.777-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:32:00+00:00, run_id=scheduled__2024-07-03T20:32:00+00:00, run_start_date=2024-07-03 20:33:01.954941+00:00, run_end_date=2024-07-03 20:33:06.777617+00:00, run_duration=4.822676, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:32:00+00:00, data_interval_end=2024-07-03 20:33:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:33:06.779-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:33:00+00:00, run_after=2024-07-03 20:34:00+00:00[0m
[[34m2024-07-03T17:34:01.334-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:34:00+00:00, run_after=2024-07-03 20:35:00+00:00[0m
[[34m2024-07-03T17:34:01.372-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:33:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:34:01.373-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:34:01.373-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:33:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:34:01.374-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:34:01.375-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:33:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:34:01.375-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:34:01.379-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:34:02.516-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:33:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:34:02.604-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:33:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:34:06.264-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:33:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:34:06.269-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:33:00+00:00, map_index=-1, run_start_date=2024-07-03 20:34:02.655537+00:00, run_end_date=2024-07-03 20:34:06.039563+00:00, run_duration=3.384026, state=success, executor_state=success, try_number=1, max_tries=0, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:34:01.373934+00:00, queued_by_job_id=1, pid=190401[0m
[[34m2024-07-03T17:34:06.308-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:33:00+00:00: scheduled__2024-07-03T20:33:00+00:00, state:running, queued_at: 2024-07-03 20:34:01.328492+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:34:06.308-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:33:00+00:00, run_id=scheduled__2024-07-03T20:33:00+00:00, run_start_date=2024-07-03 20:34:01.345058+00:00, run_end_date=2024-07-03 20:34:06.308834+00:00, run_duration=4.963776, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:33:00+00:00, data_interval_end=2024-07-03 20:34:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:34:06.313-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:34:00+00:00, run_after=2024-07-03 20:35:00+00:00[0m
[[34m2024-07-03T17:35:01.196-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:35:00+00:00, run_after=2024-07-03 20:36:00+00:00[0m
[[34m2024-07-03T17:35:01.231-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:34:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:35:01.231-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:35:01.231-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:34:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:35:01.233-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:35:01.233-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:34:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:35:01.233-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:35:01.237-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:35:01.989-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:34:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:35:02.060-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:34:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:35:05.700-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:34:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:35:05.705-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:34:00+00:00, map_index=-1, run_start_date=2024-07-03 20:35:02.091057+00:00, run_end_date=2024-07-03 20:35:05.383102+00:00, run_duration=3.292045, state=success, executor_state=success, try_number=1, max_tries=0, job_id=26, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:35:01.232132+00:00, queued_by_job_id=1, pid=190823[0m
[[34m2024-07-03T17:35:05.740-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:34:00+00:00: scheduled__2024-07-03T20:34:00+00:00, state:running, queued_at: 2024-07-03 20:35:01.188035+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:35:05.741-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:34:00+00:00, run_id=scheduled__2024-07-03T20:34:00+00:00, run_start_date=2024-07-03 20:35:01.207147+00:00, run_end_date=2024-07-03 20:35:05.741197+00:00, run_duration=4.53405, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:34:00+00:00, data_interval_end=2024-07-03 20:35:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:35:05.745-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:35:00+00:00, run_after=2024-07-03 20:36:00+00:00[0m
[[34m2024-07-03T17:36:02.918-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:36:00+00:00, run_after=2024-07-03 20:37:00+00:00[0m
[[34m2024-07-03T17:36:02.947-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:35:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:36:02.947-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:36:02.947-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:35:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:36:02.948-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:36:02.949-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:35:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:36:02.949-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:36:02.953-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:36:03.703-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:35:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:36:03.809-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:35:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:36:07.601-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:35:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:36:07.608-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:35:00+00:00, map_index=-1, run_start_date=2024-07-03 20:36:03.852182+00:00, run_end_date=2024-07-03 20:36:07.294987+00:00, run_duration=3.442805, state=success, executor_state=success, try_number=1, max_tries=0, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:36:02.948275+00:00, queued_by_job_id=1, pid=191209[0m
[[34m2024-07-03T17:36:07.744-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:35:00+00:00: scheduled__2024-07-03T20:35:00+00:00, state:running, queued_at: 2024-07-03 20:36:02.915648+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:36:07.744-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:35:00+00:00, run_id=scheduled__2024-07-03T20:35:00+00:00, run_start_date=2024-07-03 20:36:02.926732+00:00, run_end_date=2024-07-03 20:36:07.744844+00:00, run_duration=4.818112, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:35:00+00:00, data_interval_end=2024-07-03 20:36:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:36:07.747-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:36:00+00:00, run_after=2024-07-03 20:37:00+00:00[0m
[[34m2024-07-03T17:36:12.201-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:37:01.310-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:37:00+00:00, run_after=2024-07-03 20:38:00+00:00[0m
[[34m2024-07-03T17:37:01.337-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:36:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:37:01.337-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:37:01.337-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:36:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:37:01.338-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:37:01.338-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:36:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:37:01.339-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:37:01.342-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:37:02.139-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:36:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:37:02.218-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:36:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:37:06.502-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:36:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:37:06.507-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:36:00+00:00, map_index=-1, run_start_date=2024-07-03 20:37:02.248202+00:00, run_end_date=2024-07-03 20:37:06.216902+00:00, run_duration=3.9687, state=success, executor_state=success, try_number=1, max_tries=0, job_id=28, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:37:01.337903+00:00, queued_by_job_id=1, pid=191566[0m
[[34m2024-07-03T17:37:08.661-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:36:00+00:00: scheduled__2024-07-03T20:36:00+00:00, state:running, queued_at: 2024-07-03 20:37:01.306543+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:37:08.662-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:36:00+00:00, run_id=scheduled__2024-07-03T20:36:00+00:00, run_start_date=2024-07-03 20:37:01.318854+00:00, run_end_date=2024-07-03 20:37:08.662314+00:00, run_duration=7.34346, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:36:00+00:00, data_interval_end=2024-07-03 20:37:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:37:08.668-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:37:00+00:00, run_after=2024-07-03 20:38:00+00:00[0m
[[34m2024-07-03T17:38:02.046-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:38:00+00:00, run_after=2024-07-03 20:39:00+00:00[0m
[[34m2024-07-03T17:38:02.089-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:37:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:38:02.089-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:38:02.090-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:37:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:38:02.091-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:38:02.092-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:37:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:38:02.092-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:38:02.096-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:38:02.820-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:37:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:38:02.894-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:37:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:38:06.474-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:37:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:38:06.478-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:37:00+00:00, map_index=-1, run_start_date=2024-07-03 20:38:02.922976+00:00, run_end_date=2024-07-03 20:38:06.186121+00:00, run_duration=3.263145, state=success, executor_state=success, try_number=1, max_tries=0, job_id=29, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:38:02.090775+00:00, queued_by_job_id=1, pid=191973[0m
[[34m2024-07-03T17:38:06.509-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:37:00+00:00: scheduled__2024-07-03T20:37:00+00:00, state:running, queued_at: 2024-07-03 20:38:02.040407+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:38:06.510-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:37:00+00:00, run_id=scheduled__2024-07-03T20:37:00+00:00, run_start_date=2024-07-03 20:38:02.062832+00:00, run_end_date=2024-07-03 20:38:06.510026+00:00, run_duration=4.447194, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:37:00+00:00, data_interval_end=2024-07-03 20:38:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:38:06.512-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:38:00+00:00, run_after=2024-07-03 20:39:00+00:00[0m
[[34m2024-07-03T17:39:01.934-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:39:00+00:00, run_after=2024-07-03 20:40:00+00:00[0m
[[34m2024-07-03T17:39:01.973-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:38:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:39:01.973-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:39:01.974-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:38:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:39:01.975-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:39:01.976-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:38:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:39:01.976-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:39:01.981-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:39:02.652-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:38:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:39:02.723-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:38:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:39:06.198-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:38:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:39:06.202-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:38:00+00:00, map_index=-1, run_start_date=2024-07-03 20:39:02.754490+00:00, run_end_date=2024-07-03 20:39:05.955881+00:00, run_duration=3.201391, state=success, executor_state=success, try_number=1, max_tries=0, job_id=30, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:39:01.974739+00:00, queued_by_job_id=1, pid=192460[0m
[[34m2024-07-03T17:39:06.230-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:38:00+00:00: scheduled__2024-07-03T20:38:00+00:00, state:running, queued_at: 2024-07-03 20:39:01.929170+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:39:06.230-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:38:00+00:00, run_id=scheduled__2024-07-03T20:38:00+00:00, run_start_date=2024-07-03 20:39:01.946548+00:00, run_end_date=2024-07-03 20:39:06.230746+00:00, run_duration=4.284198, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:38:00+00:00, data_interval_end=2024-07-03 20:39:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:39:06.233-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:39:00+00:00, run_after=2024-07-03 20:40:00+00:00[0m
[[34m2024-07-03T17:40:01.038-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:40:00+00:00, run_after=2024-07-03 20:41:00+00:00[0m
[[34m2024-07-03T17:40:01.077-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:39:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:40:01.078-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:40:01.078-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:39:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:40:01.079-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:40:01.080-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:39:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:40:01.080-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:40:01.084-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:40:01.806-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:39:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:40:01.879-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:39:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:40:05.287-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:39:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:40:05.291-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:39:00+00:00, map_index=-1, run_start_date=2024-07-03 20:40:01.909079+00:00, run_end_date=2024-07-03 20:40:05.046468+00:00, run_duration=3.137389, state=success, executor_state=success, try_number=1, max_tries=0, job_id=31, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:40:01.078818+00:00, queued_by_job_id=1, pid=192852[0m
[[34m2024-07-03T17:40:05.324-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:39:00+00:00: scheduled__2024-07-03T20:39:00+00:00, state:running, queued_at: 2024-07-03 20:40:01.033096+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:40:05.324-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:39:00+00:00, run_id=scheduled__2024-07-03T20:39:00+00:00, run_start_date=2024-07-03 20:40:01.053302+00:00, run_end_date=2024-07-03 20:40:05.324426+00:00, run_duration=4.271124, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:39:00+00:00, data_interval_end=2024-07-03 20:40:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:40:05.326-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:40:00+00:00, run_after=2024-07-03 20:41:00+00:00[0m
[[34m2024-07-03T17:41:01.230-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:41:00+00:00, run_after=2024-07-03 20:42:00+00:00[0m
[[34m2024-07-03T17:41:01.259-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:40:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:41:01.259-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:41:01.260-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:40:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:41:01.261-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:41:01.261-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:40:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:41:01.261-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:41:01.265-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:41:01.922-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:40:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:41:01.994-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:40:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:41:05.255-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:40:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:41:05.259-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:40:00+00:00, map_index=-1, run_start_date=2024-07-03 20:41:02.022718+00:00, run_end_date=2024-07-03 20:41:05.050641+00:00, run_duration=3.027923, state=success, executor_state=success, try_number=1, max_tries=0, job_id=32, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:41:01.260615+00:00, queued_by_job_id=1, pid=193259[0m
[[34m2024-07-03T17:41:05.292-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:40:00+00:00: scheduled__2024-07-03T20:40:00+00:00, state:running, queued_at: 2024-07-03 20:41:01.226825+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:41:05.293-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:40:00+00:00, run_id=scheduled__2024-07-03T20:40:00+00:00, run_start_date=2024-07-03 20:41:01.241284+00:00, run_end_date=2024-07-03 20:41:05.293101+00:00, run_duration=4.051817, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:40:00+00:00, data_interval_end=2024-07-03 20:41:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:41:05.297-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:41:00+00:00, run_after=2024-07-03 20:42:00+00:00[0m
[[34m2024-07-03T17:41:12.254-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:42:01.148-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:42:00+00:00, run_after=2024-07-03 20:43:00+00:00[0m
[[34m2024-07-03T17:42:01.195-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:41:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:42:01.196-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:42:01.196-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:41:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:42:01.198-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:42:01.198-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:41:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:42:01.199-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:42:01.203-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:42:01.818-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:41:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:42:01.879-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:41:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:42:05.411-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:41:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:42:05.417-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:41:00+00:00, map_index=-1, run_start_date=2024-07-03 20:42:01.904426+00:00, run_end_date=2024-07-03 20:42:05.147480+00:00, run_duration=3.243054, state=success, executor_state=success, try_number=1, max_tries=0, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:42:01.196988+00:00, queued_by_job_id=1, pid=193660[0m
[[34m2024-07-03T17:42:05.452-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:41:00+00:00: scheduled__2024-07-03T20:41:00+00:00, state:running, queued_at: 2024-07-03 20:42:01.142234+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:42:05.452-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:41:00+00:00, run_id=scheduled__2024-07-03T20:41:00+00:00, run_start_date=2024-07-03 20:42:01.164368+00:00, run_end_date=2024-07-03 20:42:05.452666+00:00, run_duration=4.288298, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:41:00+00:00, data_interval_end=2024-07-03 20:42:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:42:05.455-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:42:00+00:00, run_after=2024-07-03 20:43:00+00:00[0m
[[34m2024-07-03T17:43:01.112-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:43:00+00:00, run_after=2024-07-03 20:44:00+00:00[0m
[[34m2024-07-03T17:43:01.162-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:42:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:43:01.162-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:43:01.162-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:42:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:43:01.163-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:43:01.163-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:42:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:43:01.163-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:43:01.166-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:43:02.072-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:42:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:43:02.218-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:42:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:43:05.884-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:42:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:43:05.891-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:42:00+00:00, map_index=-1, run_start_date=2024-07-03 20:43:02.267265+00:00, run_end_date=2024-07-03 20:43:05.610909+00:00, run_duration=3.343644, state=success, executor_state=success, try_number=1, max_tries=0, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:43:01.162859+00:00, queued_by_job_id=1, pid=194027[0m
[[34m2024-07-03T17:43:06.039-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:42:00+00:00: scheduled__2024-07-03T20:42:00+00:00, state:running, queued_at: 2024-07-03 20:43:01.101357+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:43:06.039-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:42:00+00:00, run_id=scheduled__2024-07-03T20:42:00+00:00, run_start_date=2024-07-03 20:43:01.135178+00:00, run_end_date=2024-07-03 20:43:06.039453+00:00, run_duration=4.904275, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:42:00+00:00, data_interval_end=2024-07-03 20:43:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:43:06.043-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:43:00+00:00, run_after=2024-07-03 20:44:00+00:00[0m
[[34m2024-07-03T17:44:01.607-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:44:00+00:00, run_after=2024-07-03 20:45:00+00:00[0m
[[34m2024-07-03T17:44:01.641-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:43:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:44:01.641-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:44:01.642-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:43:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:44:01.643-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:44:01.644-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:43:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:44:01.644-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:44:01.648-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:44:02.387-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:43:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:44:02.459-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:43:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:44:05.937-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:43:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:44:05.941-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:43:00+00:00, map_index=-1, run_start_date=2024-07-03 20:44:02.488590+00:00, run_end_date=2024-07-03 20:44:05.670433+00:00, run_duration=3.181843, state=success, executor_state=success, try_number=1, max_tries=0, job_id=35, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:44:01.642588+00:00, queued_by_job_id=1, pid=194417[0m
[[34m2024-07-03T17:44:05.975-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:43:00+00:00: scheduled__2024-07-03T20:43:00+00:00, state:running, queued_at: 2024-07-03 20:44:01.604132+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:44:05.975-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:43:00+00:00, run_id=scheduled__2024-07-03T20:43:00+00:00, run_start_date=2024-07-03 20:44:01.618424+00:00, run_end_date=2024-07-03 20:44:05.975380+00:00, run_duration=4.356956, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:43:00+00:00, data_interval_end=2024-07-03 20:44:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:44:05.978-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:44:00+00:00, run_after=2024-07-03 20:45:00+00:00[0m
[[34m2024-07-03T17:45:01.407-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:45:00+00:00, run_after=2024-07-03 20:46:00+00:00[0m
[[34m2024-07-03T17:45:01.428-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:44:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:45:01.428-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:45:01.429-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:44:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:45:01.429-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:45:01.429-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:44:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:45:01.430-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:45:01.433-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:45:02.084-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:44:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:45:02.156-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:44:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:45:05.786-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:44:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:45:05.790-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:44:00+00:00, map_index=-1, run_start_date=2024-07-03 20:45:02.188633+00:00, run_end_date=2024-07-03 20:45:05.561581+00:00, run_duration=3.372948, state=success, executor_state=success, try_number=1, max_tries=0, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:45:01.429266+00:00, queued_by_job_id=1, pid=194830[0m
[[34m2024-07-03T17:45:05.818-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:44:00+00:00: scheduled__2024-07-03T20:44:00+00:00, state:running, queued_at: 2024-07-03 20:45:01.404665+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:45:05.818-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:44:00+00:00, run_id=scheduled__2024-07-03T20:44:00+00:00, run_start_date=2024-07-03 20:45:01.415326+00:00, run_end_date=2024-07-03 20:45:05.818218+00:00, run_duration=4.402892, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:44:00+00:00, data_interval_end=2024-07-03 20:45:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:45:05.820-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:45:00+00:00, run_after=2024-07-03 20:46:00+00:00[0m
[[34m2024-07-03T17:46:01.290-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:46:00+00:00, run_after=2024-07-03 20:47:00+00:00[0m
[[34m2024-07-03T17:46:01.320-0300[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:45:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:46:01.320-0300[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG csv_to_csv has 0/16 running and queued tasks[0m
[[34m2024-07-03T17:46:01.320-0300[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:45:00+00:00 [scheduled]>[0m
[[34m2024-07-03T17:46:01.321-0300[0m] {[34mtaskinstance.py:[0m2260} WARNING[0m - cannot record scheduled_duration for task run_meltano_task because previous state change time has not been saved[0m
[[34m2024-07-03T17:46:01.321-0300[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:45:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-03T17:46:01.321-0300[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:46:01.325-0300[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'csv_to_csv', 'run_meltano_task', 'scheduled__2024-07-03T20:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/csv-to-csv.py'][0m
[[34m2024-07-03T17:46:01.982-0300[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/gabriela/Documents/meltano-lighthouse/fonte-csv/orchestrate/airflow/dags/csv-to-csv.py[0m
Changing /home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/logs/dag_id=csv_to_csv/run_id=scheduled__2024-07-03T20:45:00+00:00/task_id=run_meltano_task permission to 509
[[34m2024-07-03T17:46:02.054-0300[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: csv_to_csv.run_meltano_task scheduled__2024-07-03T20:45:00+00:00 [queued]> on host gabriela-Inspiron-15-3520[0m
[[34m2024-07-03T17:46:05.338-0300[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='csv_to_csv', task_id='run_meltano_task', run_id='scheduled__2024-07-03T20:45:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-03T17:46:05.344-0300[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=csv_to_csv, task_id=run_meltano_task, run_id=scheduled__2024-07-03T20:45:00+00:00, map_index=-1, run_start_date=2024-07-03 20:46:02.085671+00:00, run_end_date=2024-07-03 20:46:05.101552+00:00, run_duration=3.015881, state=success, executor_state=success, try_number=1, max_tries=0, job_id=37, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-03 20:46:01.321153+00:00, queued_by_job_id=1, pid=195301[0m
[[34m2024-07-03T17:46:05.378-0300[0m] {[34mdagrun.py:[0m732} INFO[0m - Marking run <DagRun csv_to_csv @ 2024-07-03 20:45:00+00:00: scheduled__2024-07-03T20:45:00+00:00, state:running, queued_at: 2024-07-03 20:46:01.288065+00:00. externally triggered: False> successful[0m
[[34m2024-07-03T17:46:05.379-0300[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=csv_to_csv, execution_date=2024-07-03 20:45:00+00:00, run_id=scheduled__2024-07-03T20:45:00+00:00, run_start_date=2024-07-03 20:46:01.303971+00:00, run_end_date=2024-07-03 20:46:05.379209+00:00, run_duration=4.075238, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 20:45:00+00:00, data_interval_end=2024-07-03 20:46:00+00:00, dag_hash=ab92631ccc5c98094d60c95ec7bf972e[0m
[[34m2024-07-03T17:46:05.382-0300[0m] {[34mdag.py:[0m3823} INFO[0m - Setting next_dagrun for csv_to_csv to 2024-07-03 20:46:00+00:00, run_after=2024-07-03 20:47:00+00:00[0m
[[34m2024-07-03T17:46:12.307-0300[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-03T17:46:16.705-0300[0m] {[34mscheduler_job_runner.py:[0m872} ERROR[0m - Exception when executing SchedulerJob._run_scheduler_loop[0m
Traceback (most recent call last):
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 327, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/create.py", line 574, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 598, in connect
sqlite3.OperationalError: unable to open database file

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 855, in _execute
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 987, in _run_scheduler_loop
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1061, in _do_scheduling
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 91, in wrapped_function
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 347, in __iter__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 325, in iter
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 158, in reraise
  File "/home/gabriela/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/home/gabriela/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 100, in wrapped_function
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1127, in _create_dagruns_for_dags
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/models/dag.py", line 3742, in dags_needing_dagruns
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/future/engine.py", line 412, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 327, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/create.py", line 574, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 598, in connect
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2024-07-03T17:46:16.739-0300[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 181459. PIDs of all processes in the group: [][0m
[[34m2024-07-03T17:46:16.740-0300[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 181459[0m
[[34m2024-07-03T17:46:16.740-0300[0m] {[34mprocess_utils.py:[0m100} INFO[0m - Sending the signal Signals.SIGTERM to process 181459 as process group is missing.[0m
[[34m2024-07-03T17:46:16.741-0300[0m] {[34mscheduler_job_runner.py:[0m884} INFO[0m - Exited execute loop[0m
[[34m2024-07-03T17:46:16.742-0300[0m] {[34mscheduler_command.py:[0m54} ERROR[0m - Exception when running scheduler job[0m
Traceback (most recent call last):
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 327, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/create.py", line 574, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 598, in connect
sqlite3.OperationalError: unable to open database file

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 393, in run_job
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 422, in execute_job
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 855, in _execute
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 987, in _run_scheduler_loop
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1061, in _do_scheduling
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 91, in wrapped_function
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 347, in __iter__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 325, in iter
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 158, in reraise
  File "/home/gabriela/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/home/gabriela/anaconda3/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 100, in wrapped_function
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1127, in _create_dagruns_for_dags
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/models/dag.py", line 3742, in dags_needing_dagruns
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/future/engine.py", line 412, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 327, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/create.py", line 574, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 598, in connect
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/14/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 327, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/create.py", line 574, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 598, in connect
sqlite3.OperationalError: unable to open database file

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/cli/commands/scheduler_command.py", line 52, in _run_scheduler_job
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 79, in wrapper
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 395, in run_job
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 76, in wrapper
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 240, in complete_execution
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 76, in wrapper
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 332, in _update_in_db
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2853, in get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/future/engine.py", line 412, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 327, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/create.py", line 574, in connect
  File "/home/gabriela/Documents/meltano-lighthouse/fonte-csv/.meltano/utilities/airflow/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 598, in connect
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/14/e3q8)
